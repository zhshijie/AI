"""
AIæ–°é—»åˆ†ææ¨¡å—
ä½¿ç”¨å…è´¹çš„AI APIè¿›è¡Œæ™ºèƒ½æ–°é—»åˆ†æå’ŒæŠ•èµ„å»ºè®®ç”Ÿæˆ
"""

import requests
import json
import os
from typing import List, Dict
import time

# æ”¯æŒå¤šä¸ªå…è´¹AIæœåŠ¡
AI_PROVIDERS = {
    'groq': {
        'api_url': 'https://api.groq.com/openai/v1/chat/completions',
        'api_key_env': 'GROQ_API_KEY',
        'model': 'llama-3.1-70b-versatile',
        'free': True
    },
    'openrouter': {
        'api_url': 'https://openrouter.ai/api/v1/chat/completions',
        'api_key_env': 'OPENROUTER_API_KEY',
        'model': 'meta-llama/llama-3.1-8b-instruct:free',
        'free': True,
        'site_url': 'https://github.com',
        'site_name': 'Economic News Analyzer'
    },
    'deepseek': {
        'api_url': 'https://api.deepseek.com/v1/chat/completions',
        'api_key_env': 'DEEPSEEK_API_KEY',
        'model': 'deepseek-chat',
        'free': False  # éœ€è¦ä»˜è´¹ï¼Œä½†ä»·æ ¼å¾ˆä½
    }
}

class AINewsAnalyzer:
    """AIæ–°é—»åˆ†æå™¨"""
    
    def __init__(self, provider='groq'):
        """
        åˆå§‹åŒ–AIåˆ†æå™¨
        
        Args:
            provider: AIæœåŠ¡æä¾›å•† ('groq', 'openrouter', 'deepseek')
        """
        self.provider = provider
        self.config = AI_PROVIDERS.get(provider)
        
        if not self.config:
            raise ValueError(f"ä¸æ”¯æŒçš„AIæä¾›å•†: {provider}")
        
        # ä»ç¯å¢ƒå˜é‡è·å–APIå¯†é’¥
        self.api_key = os.getenv(self.config['api_key_env'], '')
        
        if not self.api_key:
            print(f"âš ï¸  æœªè®¾ç½® {self.config['api_key_env']} ç¯å¢ƒå˜é‡ï¼Œå°†ä½¿ç”¨å¤‡ç”¨åˆ†ææ–¹æ³•")
            self.use_fallback = True
        else:
            self.use_fallback = False
            print(f"âœ“ ä½¿ç”¨ {provider} AIæœåŠ¡è¿›è¡Œåˆ†æ")
    
    def analyze_news(self, news_list: List[Dict]) -> Dict:
        """
        åˆ†ææ–°é—»åˆ—è¡¨ï¼Œç”ŸæˆæŠ•èµ„å»ºè®®
        
        Args:
            news_list: æ–°é—»åˆ—è¡¨
            
        Returns:
            åˆ†æç»“æœå­—å…¸
        """
        if self.use_fallback or not self.api_key:
            print("ä½¿ç”¨å¤‡ç”¨åˆ†ææ–¹æ³•ï¼ˆåŸºäºè§„åˆ™ï¼‰")
            return self._fallback_analysis(news_list)
        
        try:
            # å‡†å¤‡æ–°é—»æ‘˜è¦
            news_summary = self._prepare_news_summary(news_list[:30])
            
            # è°ƒç”¨AIè¿›è¡Œåˆ†æ
            analysis_result = self._call_ai_api(news_summary)
            
            if analysis_result:
                print("âœ“ AIåˆ†æå®Œæˆ")
                return analysis_result
            else:
                print("AIåˆ†æå¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ³•")
                return self._fallback_analysis(news_list)
                
        except Exception as e:
            print(f"AIåˆ†æå‡ºé”™: {str(e)}ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ³•")
            return self._fallback_analysis(news_list)
    
    def _prepare_news_summary(self, news_list: List[Dict]) -> str:
        """å‡†å¤‡æ–°é—»æ‘˜è¦æ–‡æœ¬"""
        summary_parts = []
        
        for i, news in enumerate(news_list, 1):
            title = news.get('title', '')
            description = news.get('description', '')
            category = news.get('category', '')
            source = news.get('source', '')
            
            summary_parts.append(
                f"{i}. [{category}] {title}\n"
                f"   æ¥æº: {source}\n"
                f"   æ‘˜è¦: {description[:150]}\n"
            )
        
        return "\n".join(summary_parts)
    
    def _call_ai_api(self, news_summary: str) -> Dict:
        """è°ƒç”¨AI APIè¿›è¡Œåˆ†æ"""
        
        # æ„å»ºæç¤ºè¯
        prompt = f"""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„é‡‘èåˆ†æå¸ˆå’ŒæŠ•èµ„é¡¾é—®ã€‚è¯·åŸºäºä»¥ä¸‹æœ€æ–°çš„å…¨çƒç»æµæ–°é—»ï¼Œè¿›è¡Œæ·±å…¥åˆ†æå¹¶ç»™å‡ºæŠ•èµ„å»ºè®®ã€‚

ã€æ–°é—»åˆ—è¡¨ã€‘
{news_summary}

ã€åˆ†æè¦æ±‚ã€‘
è¯·ä»ä»¥ä¸‹å‡ ä¸ªç»´åº¦è¿›è¡Œåˆ†æï¼š
1. æ•´ä½“å¸‚åœºæƒ…ç»ªï¼ˆä¹è§‚/ä¸­æ€§/è°¨æ…ï¼‰
2. æŠ•èµ„æ¸©åº¦è¯„åˆ†ï¼ˆ0-100åˆ†ï¼Œåˆ†æ•°è¶Šé«˜è¡¨ç¤ºæŠ•èµ„ä»·å€¼è¶Šé«˜ï¼‰
3. å…³é”®å½±å“å› ç´ ï¼ˆåˆ—å‡º3-5ä¸ªæœ€é‡è¦çš„å› ç´ ï¼‰
4. ç§¯æå› ç´ å’Œæ¶ˆæå› ç´ çš„æ•°é‡ç»Ÿè®¡
5. è¯¦ç»†çš„æŠ•èµ„å»ºè®®å’Œé£é™©æç¤º

ã€è¾“å‡ºæ ¼å¼ã€‘
è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºï¼ˆä¸è¦åŒ…å«ä»»ä½•å…¶ä»–æ–‡å­—ï¼‰ï¼š
{{
  "temperature_score": 75.5,
  "sentiment": "ä¹è§‚",
  "sentiment_emoji": "ğŸ˜Š",
  "analysis_text": "è¯¦ç»†çš„åˆ†ææ–‡æœ¬ï¼Œè‡³å°‘200å­—...",
  "key_factors": [
    "âœ“ å› ç´ 1: æè¿°...",
    "âœ— å› ç´ 2: æè¿°...",
    "âœ“ å› ç´ 3: æè¿°..."
  ],
  "positive_count": 15,
  "negative_count": 8,
  "neutral_count": 7,
  "investment_advice": {{
    "short_term": "çŸ­æœŸæŠ•èµ„å»ºè®®...",
    "medium_term": "ä¸­æœŸæŠ•èµ„å»ºè®®...",
    "risk_warning": "é£é™©æç¤º..."
  }}
}}

æ³¨æ„ï¼š
- temperature_scoreèŒƒå›´0-100ï¼Œ70ä»¥ä¸Šä¸ºä¹è§‚ï¼Œ50-70ä¸ºä¸­æ€§ï¼Œ50ä»¥ä¸‹ä¸ºè°¨æ…
- sentimentåªèƒ½æ˜¯"ä¹è§‚"ã€"ä¸­æ€§"æˆ–"è°¨æ…"
- sentiment_emojiå¯¹åº”ï¼šä¹è§‚ğŸ˜Šã€ä¸­æ€§ğŸ˜ã€è°¨æ…ğŸ˜Ÿ
- key_factorsç”¨âœ“è¡¨ç¤ºç§¯æå› ç´ ï¼Œâœ—è¡¨ç¤ºæ¶ˆæå› ç´ 
- analysis_textè¦è¯¦ç»†ã€ä¸“ä¸šï¼Œè‡³å°‘200å­—
"""

        try:
            headers = {
                'Authorization': f'Bearer {self.api_key}',
                'Content-Type': 'application/json'
            }
            
            # æ ¹æ®ä¸åŒçš„æä¾›å•†è®¾ç½®ä¸åŒçš„è¯·æ±‚å¤´
            if self.provider == 'openrouter':
                headers['HTTP-Referer'] = self.config.get('site_url', 'https://github.com')
                headers['X-Title'] = self.config.get('site_name', 'Economic News Analyzer')
            
            payload = {
                'model': self.config['model'],
                'messages': [
                    {
                        'role': 'system',
                        'content': 'ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„é‡‘èåˆ†æå¸ˆï¼Œæ“…é•¿åˆ†æå…¨çƒç»æµæ–°é—»å¹¶ç»™å‡ºæŠ•èµ„å»ºè®®ã€‚'
                    },
                    {
                        'role': 'user',
                        'content': prompt
                    }
                ],
                'temperature': 0.7,
                'max_tokens': 2000
            }
            
            print(f"æ­£åœ¨è°ƒç”¨ {self.provider} AI API...")
            print(f"API URL: {self.config['api_url']}")
            print(f"Model: {self.config['model']}")
            
            response = requests.post(
                self.config['api_url'],
                headers=headers,
                json=payload,
                timeout=60
            )
            
            print(f"å“åº”çŠ¶æ€ç : {response.status_code}")
            
            if response.status_code == 200:
                result = response.json()
                content = result['choices'][0]['message']['content']
                
                # æå–JSONå†…å®¹
                content = content.strip()
                if '```json' in content:
                    content = content.split('```json')[1].split('```')[0].strip()
                elif '```' in content:
                    content = content.split('```')[1].split('```')[0].strip()
                
                # è§£æJSON
                analysis_data = json.loads(content)
                
                # æ·»åŠ å…ƒæ•°æ®
                from datetime import datetime
                analysis_data['analyzed_at'] = datetime.now().isoformat()
                analysis_data['analyzed_news_count'] = len(news_summary.split('\n\n'))
                analysis_data['ai_provider'] = self.provider
                
                return analysis_data
            else:
                print(f"APIè¯·æ±‚å¤±è´¥: {response.status_code}")
                print(f"é”™è¯¯ä¿¡æ¯: {response.text}")
                return None
                
        except json.JSONDecodeError as e:
            print(f"JSONè§£æå¤±è´¥: {str(e)}")
            print(f"AIè¿”å›å†…å®¹: {content[:500]}")
            return None
        except Exception as e:
            print(f"APIè°ƒç”¨å¤±è´¥: {str(e)}")
            return None
    
    def _fallback_analysis(self, news_list: List[Dict]) -> Dict:
        """å¤‡ç”¨åˆ†ææ–¹æ³•ï¼ˆåŸºäºè§„åˆ™ï¼‰"""
        print("ä½¿ç”¨åŸºäºè§„åˆ™çš„å¤‡ç”¨åˆ†ææ–¹æ³•")
        
        # å…³é”®è¯åˆ—è¡¨
        positive_keywords = [
            'surge', 'rise', 'gain', 'growth', 'increase', 'boost', 'rally',
            'positive', 'optimistic', 'strong', 'recovery', 'improve', 'beat',
            'up', 'higher', 'advance', 'jump', 'soar', 'climb', 'exceed'
        ]
        
        negative_keywords = [
            'fall', 'drop', 'decline', 'decrease', 'loss', 'crash', 'plunge',
            'negative', 'pessimistic', 'weak', 'recession', 'concern', 'miss',
            'down', 'lower', 'tumble', 'sink', 'slump', 'slide', 'worry'
        ]
        
        positive_count = 0
        negative_count = 0
        neutral_count = 0
        key_factors = []
        
        # åˆ†ææ¯æ¡æ–°é—»
        for news in news_list[:30]:
            text = (news.get('title', '') + ' ' + news.get('description', '')).lower()
            
            pos_score = sum(1 for word in positive_keywords if word in text)
            neg_score = sum(1 for word in negative_keywords if word in text)
            
            if pos_score > neg_score:
                positive_count += 1
                if len(key_factors) < 5:
                    key_factors.append(f"âœ“ {news['category']}: {news['title'][:60]}...")
            elif neg_score > pos_score:
                negative_count += 1
                if len(key_factors) < 5:
                    key_factors.append(f"âœ— {news['category']}: {news['title'][:60]}...")
            else:
                neutral_count += 1
        
        # è®¡ç®—æŠ•èµ„æ¸©åº¦
        total = positive_count + negative_count + neutral_count
        if total > 0:
            temperature_score = ((positive_count * 1.0 + neutral_count * 0.5) / total) * 100
        else:
            temperature_score = 50.0
        
        # ç¡®å®šæƒ…ç»ª
        if temperature_score >= 70:
            sentiment = "ä¹è§‚"
            sentiment_emoji = "ğŸ˜Š"
            analysis_text = f"å½“å‰å…¨çƒç»æµæ–°é—»æ•´ä½“åå‘ç§¯æï¼ˆç§¯æ{positive_count}æ¡ï¼Œæ¶ˆæ{negative_count}æ¡ï¼‰ï¼Œå¸‚åœºæƒ…ç»ªä¹è§‚ã€‚å¤šé¡¹ç»æµæŒ‡æ ‡è¡¨ç°è‰¯å¥½ï¼ŒæŠ•èµ„è€…ä¿¡å¿ƒè¾ƒå¼ºã€‚å»ºè®®é€‚åº¦å¢åŠ é£é™©èµ„äº§é…ç½®ï¼Œå…³æ³¨ç§‘æŠ€ã€æ¶ˆè´¹ç­‰æˆé•¿æ€§æ¿å—ã€‚åŒæ—¶æ³¨æ„æ§åˆ¶ä»“ä½ï¼Œè®¾ç½®æ­¢æŸç‚¹ä½ã€‚"
        elif temperature_score >= 50:
            sentiment = "ä¸­æ€§"
            sentiment_emoji = "ğŸ˜"
            analysis_text = f"å½“å‰å…¨çƒç»æµæ–°é—»å–œå¿§å‚åŠï¼ˆç§¯æ{positive_count}æ¡ï¼Œæ¶ˆæ{negative_count}æ¡ï¼‰ï¼Œå¸‚åœºæƒ…ç»ªç›¸å¯¹ä¸­æ€§ã€‚éƒ¨åˆ†ç§¯æå› ç´ ææŒ¯å¸‚åœºä¿¡å¿ƒï¼Œä½†ä¹Ÿå­˜åœ¨ä¸€äº›ä¸ç¡®å®šæ€§ã€‚å»ºè®®ä¿æŒå‡è¡¡é…ç½®ï¼Œå…³æ³¨å¸‚åœºå˜åŒ–ï¼Œé€‚æ—¶è°ƒæ•´æŠ•èµ„ç»„åˆã€‚"
        else:
            sentiment = "è°¨æ…"
            sentiment_emoji = "ğŸ˜Ÿ"
            analysis_text = f"å½“å‰å…¨çƒç»æµæ–°é—»åå‘æ¶ˆæï¼ˆç§¯æ{positive_count}æ¡ï¼Œæ¶ˆæ{negative_count}æ¡ï¼‰ï¼Œå¸‚åœºæƒ…ç»ªè°¨æ…ã€‚å¤šé¡¹ä¸åˆ©å› ç´ å½±å“å¸‚åœºä¿¡å¿ƒï¼Œå»ºè®®é™ä½é£é™©èµ„äº§é…ç½®ï¼Œå¢åŠ é˜²å¾¡æ€§èµ„äº§æ¯”é‡ï¼Œå¯†åˆ‡å…³æ³¨å¸‚åœºåŠ¨æ€ã€‚"
        
        # ç»Ÿè®¡åˆ†ç±»åˆ†å¸ƒ
        categories_distribution = {}
        for news in news_list[:30]:
            category = news.get('category', 'å…¶ä»–')
            categories_distribution[category] = categories_distribution.get(category, 0) + 1
        
        from datetime import datetime
        return {
            'temperature_score': round(temperature_score, 1),
            'sentiment': sentiment,
            'sentiment_emoji': sentiment_emoji,
            'analysis_text': analysis_text,
            'key_factors': key_factors,
            'positive_count': positive_count,
            'negative_count': negative_count,
            'neutral_count': neutral_count,
            'analyzed_news_count': min(30, len(news_list)),
            'analyzed_at': datetime.now().isoformat(),
            'categories_distribution': categories_distribution,
            'ai_provider': 'fallback_rules'
        }


def get_analyzer(provider='groq'):
    """
    è·å–AIåˆ†æå™¨å®ä¾‹
    
    Args:
        provider: AIæœåŠ¡æä¾›å•†
        
    Returns:
        AINewsAnalyzerå®ä¾‹
    """
    return AINewsAnalyzer(provider)


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == '__main__':
    # æµ‹è¯•ä»£ç 
    analyzer = get_analyzer('groq')
    
    # æ¨¡æ‹Ÿæ–°é—»æ•°æ®
    test_news = [
        {
            'title': 'Federal Reserve Maintains Interest Rates',
            'description': 'The Fed keeps rates steady amid economic uncertainty',
            'category': 'è´§å¸æ”¿ç­–',
            'source': 'Reuters'
        }
    ]
    
    result = analyzer.analyze_news(test_news)
    print(json.dumps(result, indent=2, ensure_ascii=False))