"""
AIæ–°é—»åˆ†ææ¨¡å—
ä½¿ç”¨å…è´¹çš„AI APIè¿›è¡Œæ™ºèƒ½æ–°é—»åˆ†æå’ŒæŠ•èµ„å»ºè®®ç”Ÿæˆ
"""

import requests
import json
import os
from typing import List, Dict
import time

# æ”¯æŒå¤šä¸ªå…è´¹AIæœåŠ¡
AI_PROVIDERS = {
    'groq': {
        'api_url': 'https://api.groq.com/openai/v1/chat/completions',
        'api_key_env': 'GROQ_API_KEY',
        'model': 'llama-3.1-70b-versatile',
        'free': True
    },
    'openrouter': {
        'api_url': 'https://openrouter.ai/api/v1/chat/completions',
        'api_key_env': 'OPENROUTER_API_KEY',
        'model': 'deepseek/deepseek-r1:free',  # æ›´æ–°ä¸º2025å¹´å¯ç”¨çš„å…è´¹æ¨¡å‹
        'free': True,
        'site_url': 'https://github.com',
        'site_name': 'Economic News Analyzer'
    },
    'deepseek': {
        'api_url': 'https://api.deepseek.com/v1/chat/completions',
        'api_key_env': 'DEEPSEEK_API_KEY',
        'model': 'deepseek-chat',
        'free': False  # éœ€è¦ä»˜è´¹ï¼Œä½†ä»·æ ¼å¾ˆä½
    }
}

class AINewsAnalyzer:
    """AIæ–°é—»åˆ†æå™¨"""
    
    def __init__(self, provider='groq'):
        """
        åˆå§‹åŒ–AIåˆ†æå™¨
        
        Args:
            provider: AIæœåŠ¡æä¾›å•† ('groq', 'openrouter', 'deepseek')
        """
        self.provider = provider
        self.config = AI_PROVIDERS.get(provider)
        
        if not self.config:
            raise ValueError(f"ä¸æ”¯æŒçš„AIæä¾›å•†: {provider}")
        
        # ä»ç¯å¢ƒå˜é‡è·å–APIå¯†é’¥
        self.api_key = os.getenv(self.config['api_key_env'], '')
        
        if not self.api_key:
            print(f"âš ï¸  æœªè®¾ç½® {self.config['api_key_env']} ç¯å¢ƒå˜é‡ï¼Œå°†ä½¿ç”¨å¤‡ç”¨åˆ†ææ–¹æ³•")
            self.use_fallback = True
        else:
            self.use_fallback = False
            print(f"âœ“ ä½¿ç”¨ {provider} AI æœåŠ¡è¿›è¡Œåˆ†æ")
    
    def analyze_news(self, news_list: List[Dict]) -> Dict:
        """
        åˆ†ææ–°é—»åˆ—è¡¨ï¼Œç”ŸæˆæŠ•èµ„å»ºè®®
        
        Args:
            news_list: æ–°é—»åˆ—è¡¨
            
        Returns:
            åˆ†æç»“æœå­—å…¸
        """
        if self.use_fallback or not self.api_key:
            print("ä½¿ç”¨å¤‡ç”¨åˆ†ææ–¹æ³•ï¼ˆåŸºäºè§„åˆ™ï¼‰")
            return self._fallback_analysis(news_list)
        
        try:
            # å‡†å¤‡æ–°é—»æ‘˜è¦
            news_summary = self._prepare_news_summary(news_list[:30])
            
            # è°ƒç”¨AIè¿›è¡Œåˆ†æ
            analysis_result = self._call_ai_api(news_summary)
            
            if analysis_result:
                print("âœ“ AIåˆ†æå®Œæˆ")
                return analysis_result
            else:
                print("AIåˆ†æå¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ³•")
                return self._fallback_analysis(news_list)
                
        except Exception as e:
            print(f"AIåˆ†æå‡ºé”™: {str(e)}ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ³•")
            return self._fallback_analysis(news_list)
    
    def _prepare_news_summary(self, news_list: List[Dict]) -> str:
        """å‡†å¤‡æ–°é—»æ‘˜è¦æ–‡æœ¬"""
        summary_parts = []
        
        for i, news in enumerate(news_list, 1):
            title = news.get('title', '')
            description = news.get('description', '')
            category = news.get('category', '')
            source = news.get('source', '')
            
            summary_parts.append(
                f"{i}. [{category}] {title}"
                f"   æ¥æº: {source}"
                f"   æ‘˜è¦: {description[:150]}"
            )
        
        return "\n".join(summary_parts)
    
    def _call_ai_api(self, news_summary) -> Dict:
        """è°ƒç”¨AI APIè¿›è¡Œåˆ†æ
        
        Args:
            news_summary: å¯ä»¥æ˜¯å­—ç¬¦ä¸²ï¼ˆæ–°é—»æ‘˜è¦ï¼‰æˆ–åˆ—è¡¨ï¼ˆæ¶ˆæ¯åˆ—è¡¨ï¼‰
        """
        
        # åˆ¤æ–­ news_summary çš„ç±»å‹
        if isinstance(news_summary, list):
            # å¦‚æœæ˜¯åˆ—è¡¨ï¼Œè¯´æ˜æ˜¯ç›´æ¥ä¼ å…¥çš„ messages
            messages = news_summary
            news_count = 0  # æ— æ³•ä» messages ä¸­å‡†ç¡®è®¡ç®—æ–°é—»æ•°é‡
        else:
            # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œæ„å»ºæ ‡å‡†çš„ prompt
            prompt = f"""
ã€æ–°é—»æ‘˜è¦ã€‘
{news_summary}

ã€åˆ†æè¦æ±‚ã€‘
è¯·ä»ä»¥ä¸‹å‡ ä¸ªç»´åº¦è¿›è¡Œåˆ†æï¼š
1. æ•´ä½“å¸‚åœºæƒ…ç»ªï¼ˆä¹è§‚/ä¸­æ€§/è°¨æ…ï¼‰
2. æŠ•èµ„æ¸©åº¦è¯„åˆ†ï¼ˆ0-100åˆ†ï¼Œåˆ†æ•°è¶Šé«˜è¡¨ç¤ºæŠ•èµ„ä»·å€¼è¶Šé«˜ï¼‰
3. å…³é”®å½±å“å› ç´ ï¼ˆåˆ—å‡º3-5ä¸ªæœ€é‡è¦çš„å› ç´ ï¼‰
4. ç§¯æå› ç´ å’Œæ¶ˆæå› ç´ çš„æ•°é‡ç»Ÿè®¡
5. è¯¦ç»†çš„æŠ•èµ„å»ºè®®å’Œé£é™©æç¤º

ã€è¾“å‡ºæ ¼å¼ã€‘
è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºï¼ˆä¸è¦åŒ…å«ä»»ä½•å…¶ä»–æ–‡å­—ï¼‰ï¼š
{{
  "temperature_score": 75.5,
  "sentiment": "ä¹è§‚",
  "sentiment_emoji": "ğŸ˜Š",
  "analysis_text": "è¯¦ç»†çš„åˆ†ææ–‡æœ¬ï¼Œè‡³å°‘200å­—...",
  "key_factors": [
    "âœ“ å› ç´ 1: æè¿°...",
    "âœ— å› ç´ 2: æè¿°...",
    "âœ“ å› ç´ 3: æè¿°..."
  ],
  "positive_count": 15,
  "negative_count": 8,
  "neutral_count": 7,
  "investment_advice": {{
    "short_term": "çŸ­æœŸæŠ•èµ„å»ºè®®...",
    "medium_term": "ä¸­æœŸæŠ•èµ„å»ºè®®...",
    "risk_warning": "é£é™©æç¤º..."
  }}
}}

æ³¨æ„ï¼š
- temperature_scoreèŒƒå›´0-100ï¼Œ70ä»¥ä¸Šä¸ºä¹è§‚ï¼Œ50-70ä¸ºä¸­æ€§ï¼Œ50ä»¥ä¸‹ä¸ºè°¨æ…
- sentimentåªèƒ½æ˜¯"ä¹è§‚"ã€"ä¸­æ€§"æˆ–"è°¨æ…"
- sentiment_emojiå¯¹åº”ï¼šä¹è§‚ğŸ˜Šã€ä¸­æ€§ğŸ˜ã€è°¨æ…ğŸ˜Ÿ
- key_factorsç”¨âœ“è¡¨ç¤ºç§¯æå› ç´ ï¼Œâœ—è¡¨ç¤ºæ¶ˆæå› ç´ 
- analysis_textè¦è¯¦ç»†ã€ä¸“ä¸šï¼Œè‡³å°‘200å­—
"""
            messages = [
                {
                    'role': 'system',
                    'content': 'ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„é‡‘èåˆ†æå¸ˆï¼Œæ“…é•¿åˆ†æå…¨çƒç»æµæ–°é—»å¹¶ç»™å‡ºæŠ•èµ„å»ºè®®ã€‚'
                },
                {
                    'role': 'user',
                    'content': prompt
                }
            ]
            # è®¡ç®—æ–°é—»æ•°é‡
            news_count = len(news_summary.split('\n')) if isinstance(news_summary, str) else 0

        content = None  # åˆå§‹åŒ– content å˜é‡
        
        try:
            headers = {
                'Authorization': f'Bearer {self.api_key}',
                'Content-Type': 'application/json'
            }
            
            # æ ¹æ®ä¸åŒçš„æä¾›å•†è®¾ç½®ä¸åŒçš„è¯·æ±‚å¤´
            if self.provider == 'openrouter':
                headers['HTTP-Referer'] = self.config.get('site_url', 'https://github.com')
                headers['X-Title'] = self.config.get('site_name', 'Economic News Analyzer')
            
            payload = {
                'model': self.config['model'],
                'messages': messages,
                'temperature': 0.7,
                'max_tokens': 2000
            }
            
            print(f"æ­£åœ¨è°ƒç”¨ {self.provider} AI API...")
            print(f"API URL: {self.config['api_url']}")
            print(f"Model: {self.config['model']}")
            
            response = requests.post(
                self.config['api_url'],
                headers=headers,
                json=payload,
                timeout=60
            )
            
            print(f"å“åº”çŠ¶æ€ç : {response.status_code}")
            
            if response.status_code == 200:
                try:
                    result = response.json()
                    
                    # æ£€æŸ¥å“åº”ç»“æ„
                    if 'choices' not in result or len(result['choices']) == 0:
                        print(f"âŒ APIå“åº”æ ¼å¼é”™è¯¯: ç¼ºå°‘ choices å­—æ®µ")
                        print(f"å®Œæ•´å“åº”: {json.dumps(result, indent=2, ensure_ascii=False)[:1000]}")
                        return None
                    
                    content = result['choices'][0]['message']['content']
                    print(f"âœ“ è·å–åˆ°AIå“åº”å†…å®¹ï¼Œé•¿åº¦: {len(content)} å­—ç¬¦")
                    
                    # æå–JSONå†…å®¹
                    content = content.strip()
                    
                    # å°è¯•å¤šç§æ–¹å¼æå–JSON
                    if '```json' in content:
                        content = content.split('```json')[1].split('```')[0].strip()
                    elif '```' in content:
                        content = content.split('```')[1].split('```')[0].strip()
                    
                    # å¦‚æœå†…å®¹ä»¥ { å¼€å¤´ä½†ä¸å®Œæ•´ï¼Œå°è¯•æ‰¾åˆ°å®Œæ•´çš„JSON
                    if content.startswith('{') and not content.endswith('}'):
                        print(f"âš ï¸  æ£€æµ‹åˆ°ä¸å®Œæ•´çš„JSONå“åº”")
                        # å°è¯•æ‰¾åˆ°æœ€åä¸€ä¸ªå®Œæ•´çš„ }
                        last_brace = content.rfind('}')
                        if last_brace > 0:
                            content = content[:last_brace + 1]
                            print(f"âœ“ ä¿®å¤åçš„å†…å®¹é•¿åº¦: {len(content)} å­—ç¬¦")
                    
                    print(f"å‡†å¤‡è§£æçš„JSONå†…å®¹ï¼ˆå‰200å­—ç¬¦ï¼‰: {content[:200]}")
                    
                    # è§£æJSON
                    analysis_data = json.loads(content)
                    
                    # éªŒè¯å¿…éœ€å­—æ®µ
                    required_fields = ['temperature_score', 'sentiment', 'analysis_text']
                    missing_fields = [f for f in required_fields if f not in analysis_data]
                    if missing_fields:
                        print(f"âŒ ç¼ºå°‘å¿…éœ€å­—æ®µ: {missing_fields}")
                        return None
                    
                    # æ·»åŠ å…ƒæ•°æ®
                    from datetime import datetime
                    analysis_data['analyzed_at'] = datetime.now().isoformat()
                    # ä¿®å¤ï¼šæ ¹æ® news_summary çš„ç±»å‹æ¥è®¡ç®—æ–°é—»æ•°é‡
                    if isinstance(news_summary, str):
                        analysis_data['analyzed_news_count'] = len(news_summary.split('\n'))
                    else:
                        # å¦‚æœæ˜¯åˆ—è¡¨ï¼Œå°è¯•ä» analysis_data ä¸­è·å–ï¼Œæˆ–è®¾ä¸º0
                        analysis_data['analyzed_news_count'] = analysis_data.get('analyzed_news_count', 0)
                    analysis_data['ai_provider'] = self.provider
                    
                    print(f"âœ“ JSONè§£ææˆåŠŸï¼Œæ¸©åº¦è¯„åˆ†: {analysis_data.get('temperature_score')}")
                    return analysis_data
                    
                except json.JSONDecodeError as e:
                    print(f"âŒ JSONè§£æå¤±è´¥: {str(e)}")
                    if content:
                        print(f"AIè¿”å›å†…å®¹ï¼ˆå‰500å­—ç¬¦ï¼‰: {content[:500]}")
                        print(f"AIè¿”å›å†…å®¹ï¼ˆå100å­—ç¬¦ï¼‰: {content[-100:]}")
                    else:
                        print(f"AIè¿”å›çš„åŸå§‹å“åº”: {response.text[:1000]}")
                    return None
                    
            else:
                print(f"âŒ APIè¯·æ±‚å¤±è´¥: {response.status_code}")
                print(f"é”™è¯¯è¯¦æƒ…: {response.text[:500]}")
                print(f"è¯·æ±‚URL: {self.config['api_url']}")
                print(f"ä½¿ç”¨æ¨¡å‹: {self.config['model']}")
                
                if response.status_code == 404:
                    print("å¯èƒ½çš„åŸå› :")
                    print("1. API URL ä¸æ­£ç¡®")
                    print("2. æ¨¡å‹åç§°ä¸æ­£ç¡®æˆ–ä¸å¯ç”¨")
                    print("3. API ç«¯ç‚¹å·²æ›´æ”¹")
                    print("å»ºè®®:")
                    print("- è¿è¡Œæµ‹è¯•è„šæœ¬: python test_openrouter_debug.py")
                    print("- æˆ–åˆ‡æ¢åˆ° Groq: export AI_PROVIDER='groq'")
                elif response.status_code == 401:
                    print("è®¤è¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥APIå¯†é’¥æ˜¯å¦æ­£ç¡®")
                elif response.status_code == 429:
                    print("è¯·æ±‚è¿‡äºé¢‘ç¹ï¼Œè¯·ç¨åå†è¯•")
                
                return None
                
        except requests.exceptions.Timeout:
            print(f"âŒ APIè¯·æ±‚è¶…æ—¶ï¼ˆ60ç§’ï¼‰")
            return None
        except requests.exceptions.ConnectionError as e:
            print(f"âŒ ç½‘ç»œè¿æ¥é”™è¯¯: {str(e)}")
            return None
        except Exception as e:
            print(f"âŒ APIè°ƒç”¨å¤±è´¥: {type(e).__name__}: {str(e)}")
            import traceback
            print(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯:{traceback.format_exc()}")
            return None
    
    def _fallback_analysis(self, news_list: List[Dict]) -> Dict:
        """å¤‡ç”¨åˆ†ææ–¹æ³•ï¼ˆåŸºäºè§„åˆ™ï¼‰"""
        print("ä½¿ç”¨åŸºäºè§„åˆ™çš„å¤‡ç”¨åˆ†ææ–¹æ³•")
        
        # å…³é”®è¯åˆ—è¡¨
        positive_keywords = [
            'surge', 'rise', 'gain', 'growth', 'increase', 'boost', 'rally',
            'positive', 'optimistic', 'strong', 'recovery', 'improve', 'beat',
            'up', 'higher', 'advance', 'jump', 'soar', 'climb', 'exceed'
        ]
        
        negative_keywords = [
            'fall', 'drop', 'decline', 'decrease', 'loss', 'crash', 'plunge',
            'negative', 'pessimistic', 'weak', 'recession', 'concern', 'miss',
            'down', 'lower', 'tumble', 'sink', 'slump', 'slide', 'worry'
        ]
        
        positive_count = 0
        negative_count = 0
        neutral_count = 0
        key_factors = []
        
        # åˆ†ææ¯æ¡æ–°é—»
        for news in news_list[:30]:
            text = (news.get('title', '') + ' ' + news.get('description', '')).lower()
            
            pos_score = sum(1 for word in positive_keywords if word in text)
            neg_score = sum(1 for word in negative_keywords if word in text)
            
            if pos_score > neg_score:
                positive_count += 1
                if len(key_factors) < 5:
                    key_factors.append(f"âœ“ {news['category']}: {news['title'][:60]}...")
            elif neg_score > pos_score:
                negative_count += 1
                if len(key_factors) < 5:
                    key_factors.append(f"âœ— {news['category']}: {news['title'][:60]}...")
            else:
                neutral_count += 1
        
        # è®¡ç®—æŠ•èµ„æ¸©åº¦
        total = positive_count + negative_count + neutral_count
        if total > 0:
            temperature_score = ((positive_count * 1.0 + neutral_count * 0.5) / total) * 100
        else:
            temperature_score = 50.0
        
        # ç¡®å®šæƒ…ç»ª
        if temperature_score >= 70:
            sentiment = "ä¹è§‚"
            sentiment_emoji = "ğŸ˜Š"
            analysis_text = f"å½“å‰å…¨çƒç»æµæ–°é—»æ•´ä½“åå‘ç§¯æï¼ˆç§¯æ{positive_count}æ¡ï¼Œæ¶ˆæ{negative_count}æ¡ï¼‰ï¼Œå¸‚åœºæƒ…ç»ªä¹è§‚ã€‚å¤šé¡¹ç»æµæŒ‡æ ‡è¡¨ç°è‰¯å¥½ï¼ŒæŠ•èµ„è€…ä¿¡å¿ƒè¾ƒå¼ºã€‚å»ºè®®é€‚åº¦å¢åŠ é£é™©èµ„äº§é…ç½®ï¼Œå…³æ³¨ç§‘æŠ€ã€æ¶ˆè´¹ç­‰æˆé•¿æ€§æ¿å—ã€‚åŒæ—¶æ³¨æ„æ§åˆ¶ä»“ä½ï¼Œè®¾ç½®æ­¢æŸç‚¹ä½ã€‚"
        elif temperature_score >= 50:
            sentiment = "ä¸­æ€§"
            sentiment_emoji = "ğŸ˜"
            analysis_text = f"å½“å‰å…¨çƒç»æµæ–°é—»å–œå¿§å‚åŠï¼ˆç§¯æ{positive_count}æ¡ï¼Œæ¶ˆæ{negative_count}æ¡ï¼‰ï¼Œå¸‚åœºæƒ…ç»ªç›¸å¯¹ä¸­æ€§ã€‚éƒ¨åˆ†ç§¯æå› ç´ ææŒ¯å¸‚åœºä¿¡å¿ƒï¼Œä½†ä¹Ÿå­˜åœ¨ä¸€äº›ä¸ç¡®å®šæ€§ã€‚å»ºè®®ä¿æŒå‡è¡¡é…ç½®ï¼Œå…³æ³¨å¸‚åœºå˜åŒ–ï¼Œé€‚æ—¶è°ƒæ•´æŠ•èµ„ç»„åˆã€‚"
        else:
            sentiment = "è°¨æ…"
            sentiment_emoji = "ğŸ˜Ÿ"
            analysis_text = f"å½“å‰å…¨çƒç»æµæ–°é—»åå‘æ¶ˆæï¼ˆç§¯æ{positive_count}æ¡ï¼Œæ¶ˆæ{negative_count}æ¡ï¼‰ï¼Œå¸‚åœºæƒ…ç»ªè°¨æ…ã€‚å¤šé¡¹ä¸åˆ©å› ç´ å½±å“å¸‚åœºä¿¡å¿ƒï¼Œå»ºè®®é™ä½é£é™©èµ„äº§é…ç½®ï¼Œå¢åŠ é˜²å¾¡æ€§èµ„äº§æ¯”é‡ï¼Œå¯†åˆ‡å…³æ³¨å¸‚åœºåŠ¨æ€ã€‚"
        
        # ç»Ÿè®¡åˆ†ç±»åˆ†å¸ƒ
        categories_distribution = {}
        for news in news_list[:30]:
            category = news.get('category', 'å…¶ä»–')
            categories_distribution[category] = categories_distribution.get(category, 0) + 1
        
        from datetime import datetime
        return {
            'temperature_score': round(temperature_score, 1),
            'sentiment': sentiment,
            'sentiment_emoji': sentiment_emoji,
            'analysis_text': analysis_text,
            'key_factors': key_factors,
            'positive_count': positive_count,
            'negative_count': negative_count,
            'neutral_count': neutral_count,
            'analyzed_news_count': min(30, len(news_list)),
            'analyzed_at': datetime.now().isoformat(),
            'categories_distribution': categories_distribution,
            'ai_provider': 'fallback_rules'
        }


def get_analyzer(provider='groq'):
    """
    è·å–AIåˆ†æå™¨å®ä¾‹
    
    Args:
        provider: AIæœåŠ¡æä¾›å•†
        
    Returns:
        AINewsAnalyzerå®ä¾‹
    """
    return AINewsAnalyzer(provider)


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == '__main__':
    # æµ‹è¯•ä»£ç 
    analyzer = get_analyzer('groq')
    
    # æ¨¡æ‹Ÿæ–°é—»æ•°æ®
    test_news = [
        {
            'title': 'Federal Reserve Maintains Interest Rates',
            'description': 'The Fed keeps rates steady amid economic uncertainty',
            'category': 'è´§å¸æ”¿ç­–',
            'source': 'Reuters'
        }
    ]
    
    result = analyzer.analyze_news(test_news)
    print(json.dumps(result, indent=2, ensure_ascii=False))
